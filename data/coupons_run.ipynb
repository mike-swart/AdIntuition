{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import urllib\n",
    "from scipy.stats import mannwhitneyu\n",
    "import re\n",
    "import os.path\n",
    "from langdetect import detect\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "import fastcluster\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "import sys\n",
    "from scipy.cluster.hierarchy import fcluster, dendrogram\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import math\n",
    "import gensim \n",
    "import hdbscan\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.setrecursionlimit(100000)\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []\n",
    "with open(\"sentences_en.tsv\", 'rb') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        videos.append([row[0], row[1], row[2], row[3]])\n",
    "        \n",
    "videos_en_new = pd.DataFrame(videos, columns=['id', 'description', 'channelTitle', 'sentence'])\n",
    "del videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos_en_new = videos_en_new[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(line):\n",
    "    if (line is None):\n",
    "        line = ''\n",
    "    printable = set(string.printable)\n",
    "    line = ''.join(filter(lambda x: x in printable, line)) \n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    tokenizer = nltk.RegexpTokenizer(r'[a-zA-Z]*\\'[a-zA-Z]*|\\w+')\n",
    "    \n",
    "    tokens = []\n",
    "    \n",
    "    line = re.sub(r'(http[s]?://|www.)(?:[a-zA-Z]|[0-9]|[$-_@.&+]*|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))*', '', line).lower()\n",
    "    tokens.extend(tokenizer.tokenize(line))\n",
    "    \n",
    "    tokens_ = [f.strip(string.punctuation) for f in tokens]\n",
    "    tokens_ = [f for f in tokens_ if f != '' and f not in stopwords and len(f) != 1]\n",
    "    tokens_ = [f for f in tokens_ if not (f.isdigit() or f[0] == '-' and f[1:].isdigit())]\n",
    "    tokens_ = [stemmer.stem(f) for f in tokens_]\n",
    "\n",
    "    return tokens_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "countVec = CountVectorizer(tokenizer=tokenize).fit(videos_en_new['sentence'])\n",
    "#try with binary=True as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineVec = countVec.transform(videos_en_new['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155345, 68515)\n"
     ]
    }
   ],
   "source": [
    "print lineVec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clusterer = hdbscan.HDBSCAN(min_cluster_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer.fit(lineVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_en_new[\"cluster\"] = clusterer.labels_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
